{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 2 : Arbre de désision, Bayes naïf et KNN\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             | LEMARCHANT HUGO - LEMH03039705 * TAN ELODIE - TANE25619607 * JACQUES-SYLVAIN LECOINTRE LECJ19128301 |\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Automne 2018                                            |\n",
    "| Groupe                | C                                                       |\n",
    "| Numéro du laboratoire | 02                                                      |\n",
    "| Professeur            | Prof. Hervé Lombaert                                    |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 11/10/2018                                              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os, random\n",
    "import math\n",
    "import collections\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import scipy.ndimage as nd\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57\n",
       "0    0.599638\n",
       "1    0.400362\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', delimiter = ',', header=None)\n",
    "X_mail = df.loc[:, 0:56].values\n",
    "Y_mail = df.loc[:, 57].values\n",
    "\n",
    "Xm_train, Xm_test, Ym_train, Ym_test = train_test_split(X_mail, Y_mail, test_size=0.20, random_state=42, stratify=Y_mail)\n",
    "df.groupby(57).count()[0].divide(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La répartition des données montre environ 60% de courriels 'non spam' et 40% de courriels 'spam' comme indiqué dans l'énoncé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La repartition des classes (60% => 0 | 40% => 1) dans les ensembles de données est bien respectée comme demontré ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repartition des donnees dans l'emsemble d'entrainement : [(0, 1324), (1, 884)]\n",
      "Repartition des donnees dans l'emsemble de test :[(0, 331), (1, 221)]\n"
     ]
    }
   ],
   "source": [
    "print('Repartition des donnees dans l\\'emsemble d\\'entrainement : {0}'.format(collections.Counter(Ym_train).most_common(2)))\n",
    "print('Repartition des donnees dans l\\'emsemble de test :{0}'.format(collections.Counter(Ym_test).most_common(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbres de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max-depth : None , 3, 5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sthree_acc = []\n",
    "sthree_f1 = []\n",
    "\n",
    "for depth in (None,3, 5, 10):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    clf = clf.fit(Xm_train, Ym_train)\n",
    "    Y_pred = clf.predict(Xm_test)\n",
    "\n",
    "    acc = accuracy_score(Ym_test, Y_pred)\n",
    "    f1 = f1_score(Ym_test, Y_pred, average='weighted') \n",
    "\n",
    "    sthree_acc.append(acc)\n",
    "    sthree_f1.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbres de décision - Accuracy & F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEKCAYAAADXdbjqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, label in zip(range(0, 4), (None, 3, 5, 10)):\n",
    "    plt.plot(sthree_acc[i], sthree_f1[i], \"o\", label='max-depth = {}'.format(label))\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim([0.85, 1])\n",
    "plt.ylim([0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbres de décision - Cross validation\n",
    "\n",
    "D'après le graphique des $Accuracy$ et $F1 scores$, on se rend compte que le meilleur hyperparamètre pour les arbres de décision pour Spam est `max-depth = 10`. La validation croisée sera donc effectuée avec l'hyperparamètre `max-depth = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth : 5 F1 score: 0.9068710206760748\n",
      "max_depth : 10 F1 score: 0.9195562848703643\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "for md in [5,10]:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = md)\n",
    "    sthree_CV_scores = cross_val_score(clf, X_mail, Y_mail, cv= K)\n",
    "    print('max_depth : {0} F1 score: {1}'.format(md,sum(sthree_CV_scores)/K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN \n",
    "#### K = 3, 5, 10, Poids = 'uniform' & Poids = 'distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sKNN_acc_uniform = []\n",
    "sKNN_f1_uniform = []\n",
    "\n",
    "sKNN_acc_distance = []\n",
    "sKNN_f1_distance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n_neigh in (3, 5, 10):\n",
    "    clf = KNeighborsClassifier(n_neighbors = n_neigh, weights='uniform')\n",
    "\n",
    "    clf = clf.fit(Xm_train, Ym_train)\n",
    "    Y_pred = clf.predict(Xm_test)\n",
    "\n",
    "    acc = accuracy_score(Ym_test, Y_pred)\n",
    "    f1 = f1_score(Ym_test, Y_pred, average='weighted') \n",
    "\n",
    "    sKNN_acc_uniform.append(acc)\n",
    "    sKNN_f1_uniform.append(f1)\n",
    "\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors = n_neigh, weights='distance')\n",
    "    clf = clf.fit(Xm_train, Ym_train)\n",
    "    Y_pred = clf.predict(Xm_test)\n",
    "\n",
    "    acc = accuracy_score(Ym_test, Y_pred)\n",
    "    f1 = f1_score(Ym_test, Y_pred, average='weighted') \n",
    "\n",
    "    sKNN_acc_distance.append(acc)\n",
    "    sKNN_f1_distance.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN - Accuracy & F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEKCAYAAADXdbjqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8VNX5x/HPQ1iCgAjiwqaAsghJ\n2A1LhSAKyo5ghaISFPlhxYVWa61WU9TWVl8C1oVqFbQ/KiIVROHnxqKolFU2USgiFQgqu+yQ8Pz+\nmMkwWUmYDEnI9/16zYs759577rnXcZ6cc+4819wdERGRSJQp6gaIiEjJp2AiIiIRUzAREZGIKZiI\niEjEFExERCRiCiYiIhKxqAUTM3vFzH40szW5rDcze8bMNpjZKjNrFbZuqJn9J/gaGq02iohI4Yhm\nz2QScE0e668FGgZfI4AXAMysOvAIkAhcDjxiZtWi2E4REYlQ1IKJu38C7Mpjk77Aax7wb+AcM6sJ\ndAc+dPdd7r4b+JC8g5KIiBSxskV47NrA5rD3W4JluZVnY2YjCPRqqFSpUusmTZpEp6UiImeoZcuW\n7XD38yKtpyiDieVQ5nmUZy90fxF4EaBNmza+dOnSwmudiEgpYGb/LYx6ivJuri1A3bD3dYDUPMpF\nRKSYKspgMhO4OXhXVztgr7tvA94HuplZteDEe7dgmYiIFFNRG+Yys9eBJKCGmW0hcIdWOQB3nwDM\nBnoAG4CDwLDgul1m9iiwJFjVGHfPayJfRESKWNSCibsPPsl6B+7IZd0rwCuRtuHYsWNs2bKFw4cP\nR1qVSFTExsZSp04dypUrV9RNEYlIUU7AR92WLVuoUqUK9erVwyyneX2RouPu7Ny5ky1btlC/fv2i\nbo5IRM7odCqHDx/m3HPPVSCRYsnMOPfcc9VzljPCGR1MAAUSKdb0+ZQzxRkfTEREJPoUTKKscuXK\noeXZs2fTsGFDvvvuu4jqvOaaa2jevDnNmjVj5MiRpKenR9rMTFJTUxk4cGCO65KSkojWj0Pr1avH\npk2bSEpKOuU6JkyYwGuvvQbA119/TYsWLWjZsiXffPNNIbUyYP78+SQnJzNp0iRSUlIKtW6RkuiM\nnoAvqBlfbOXJ99eRuucQtc6pyH3dG9OvZY6ZXApszpw53HnnnXzwwQdcdNFFEdU1depUzj77bNyd\ngQMH8uabbzJo0KBCaSdArVq1mDZtWqHVdzqNHDkytDxjxgz69u3LH/7wh3zt6+64O2XK6G8skYLS\n/zVBM77YygNvrWbrnkM4sHXPIR54azUzvtgacd0LFizgtttuY9asWVxyySUR13f22WcDkJaWxtGj\nR0867p6SksJNN93ElVdeScOGDXnppZeAwJfnfffdR1xcHPHx8bzxxhsAbNq0ibi4OAAOHTrEoEGD\nSEhI4IYbbuDQoUMApKenk5ycHNp37NixEZ/XeeedR0xMDNWrVwdg0qRJjBo1KrS+V69ezJ8/Hwj0\n+B588EGaN29Ou3bt+OGHH0Ln+tRTTzF79mzGjRvH3//+d7p06QLA008/TVxcHHFxcYwbNy50rpdd\ndhm//OUvadWqFZs3b6Zy5crcf//9tG7dmquuuorFixeTlJREgwYNmDlzJgDly5enatWqVKxYMVPv\nU6S0Us8k6Mn313HoWObhokPH0nny/XUR9U6OHDlC3759mT9/Prklopw3bx6jR4/OVn7WWWfx+eef\n57hP9+7dWbx4Mddee22uQ1LhVq1axb///W8OHDhAy5Yt6dmzJwsXLmTFihWsXLmSHTt20LZtWzp1\n6pRpvxdeeIGzzjqLVatWsWrVKlq1Cjx2ZsWKFWzdupU1awKPq9mzZ0+2Y06ePJknn3wyW/mll16a\nY89nyZLA71Tfeuutk57PgQMHaNeuHY8//ji/+c1veOmll3jooYdC63v06MHIkSOpXLky9957L8uW\nLWPixIksWrQIdycxMZHOnTtTrVo11q1bx8SJE3n++edDdSclJfHnP/+Z/v3789BDD/Hhhx+ydu1a\nhg4dSp8+fejQoQMdOnQ4aTtFSgsFk6DUPYcKVJ5f5cqVo0OHDrz88suMHz8+x226dOnCihUrClTv\n+++/z+HDhxkyZAhz587l6quvznP7vn37UrFiRSpWrEiXLl1YvHgxn376KYMHDyYmJoYLLriAzp07\ns2TJEhISEkL7ffLJJ9x1110AJCQkhNY1aNCAjRs3cuedd9KzZ0+6deuW7ZhDhgxhyJAhBTqv/Cpf\nvjy9evUCoHXr1nz44Yd5bv/pp5/Sv39/KlWqBMB1113HggUL6NOnDxdffDHt2rXLVPc11wSeehAf\nH0+FChUoV64c8fHxbNq0KSrnI1LSaZgrqNY5FQtUnl9lypRh6tSpLFmyhD/+8Y85bjNv3jxatGiR\n7XWyv3xjY2Pp06cPb7/99knbkXUozMwIJCE4uZyG0apVq8bKlStJSkriueeeY/jw4dm2mTx5co7n\nlZ+eFEDZsmU5fvx46H347zHKlSsXaldMTAxpaWl51pXXuWYEmJzqLlOmDBUqVAgtn+w4IqWVgknQ\nfd0bU7FcTKayiuViuK9744jrPuuss3j33XeZPHkyL7/8crb1GT2TrK+chrj279/Ptm3bgMCcyezZ\ns0PDZ88++yzPPvtsjm14++23OXz4MDt37mT+/PmhIa033niD9PR0tm/fzieffMLll1+eab9OnTox\nefJkANasWcOqVasA2LFjB8ePH2fAgAE8+uijLF++PNsxhwwZkuN55Xdyv169eqxYsYLjx4+zefNm\nFi9enK/9ctKpUydmzJjBwYMHOXDgANOnT+eKK6445fpEJDMNcwVlzItE626u6tWr895779GpUydq\n1KhB3759T6meAwcO0KdPH44cOUJ6ejpXXnll6A6mr7/+mo4dO+a43+WXX07Pnj357rvv+P3vf0+t\nWrXo378/CxcupHnz5pgZf/nLX7jwwgszDeXcfvvtDBs2jISEBFq0aBEKNlu3bmXYsGGhnsOf/vSn\nUzqfvHTs2JH69esTHx9PXFxcaL7mVLRq1Yrk5ORQ+4cPH07Lli01bCVSSCy/Qx3FXU4Px/rqq6+4\n7LLLiqhFp1+vXr146623KF++fKbylJSU0ES0FD+l7XMqxYuZLXP3NpHWo57JGeTdd98t6iaISCml\nYFIK6BfaIhJtmoAXEZGIKZiIiEjEFExERCRiCiYiIhIxBZMoUwr6/DtZCvrwY/fo0SPHfGAZxo0b\nx8GDB6PRzBwlJSWxadMm6tWrd9qOKVKcKJiEWzUVxsZByjmBf1dNLbSqM1LQv/fee4WSgn7lypWs\nWbOG7du38+abbxZSKwNKQgr62bNnc8455+S6/nQHE5HSTsEkw6qp8M5dsHcz4IF/37mrUAKKUtDn\nT9YU9LkdGwK9mB07dnDgwAF69uxJ8+bNiYuL44033uCZZ54hNTWVLl26hNLP33777bRp04ZmzZrx\nyCOPZKrnkUceoVWrVsTHx/P1118DgbQ1w4YNIz4+noSEBP71r38B8MEHH9C+fXtatWrF9ddfz/79\n+4FAhoOYmBjOO++8iK+DSEmk35lkmDMGjmXJEHzsUKA84eenXK1S0J96Cvrcjh3uvffeo1atWsya\nNQuAvXv3UrVqVZ5++mnmzZtHjRo1AHj88cepXr066enpdO3alVWrVoUyINeoUYPly5fz/PPP89RT\nT/H3v/+dRx99lKpVq7J69WoAdu/ezY4dO3jsscf46KOPqFSpEn/+8595+umnefjhh0NtzjgHkdJG\nwSTD3i0FK88npaA/9RT0uR07XHx8PPfeey/3338/vXr1yjV549SpU3nxxRdJS0tj27ZtrF27NlTf\nddddBwRS2WcEhY8++ogpU6aE9q9WrRrvvvsua9euDeU/O3r0KO3btz/l8xM5k2iYK0PVOgUrzyel\noD/1FPS5HTtco0aNWLZsGfHx8TzwwAOMGTMm2zbffvstTz31FHPmzGHVqlX07NkzUzr7jBTz4ans\n3T3bsd2dq6++OpT9eO3atTlmgRYpjRRMMnR9GMpleXZJuYqB8ggpBf2ppaDP7djhUlNTOeuss7jx\nxhu59957Q+2oUqUK+/btA+Cnn36iUqVKVK1alR9++IH/+7//O+mxu3Xrlula7t69m3bt2vHZZ5+x\nYcMGAA4ePMj69evzdS4iZzoNc2XImBeZMyYwtFW1TiCQRDBfEk4p6Asut2OHW716Nffddx9lypSh\nXLlyvPDCCwCMGDGCa6+9lpo1azJv3jxatmxJs2bNaNCgQa7XKNxDDz3EHXfcQVxcHDExMTzyyCNc\nd911TJo0icGDB3PkyBEAHnvsMRo1alS4Jy5SAikF/RlEKehLptL2OZXiRSnoJRuloBeRoqJgUgoo\nBb2IRJsm4EVEJGIKJiIiEjEFExERiZiCiYiIREzBJMqikYI+KSmJxo0bh35R/uOPP0bazGxy+/V9\ncnJy1DIKZ6RvjySN+8yZM3niiScA2L59O4mJibRs2ZIFCxYUQgtPyEiVP3/+fJKTkwu1bpGSKKp3\nc5nZNcB4IAb4u7s/kWX9xcArwHnALuBGd98SXJcOrA5u+p2794lmWwFmbZzF+OXj+f7A91xY6ULu\nbnU3PRv0LJS6M1LQf/DBBxGnoIdAqpI2bSK+NTxXuSWYLO769OlDnz6Bj8qcOXNo0qQJr776ar73\nT09PJyYmJlrNEzljRa1nYmYxwHPAtUBTYLCZNc2y2VPAa+6eAIwBwn9GfcjdWwRfpyWQpHyewrYD\n23CcbQe2kfJ5CrM2zoq47sJOQV9QkyZNom/fvlxzzTU0btyYP/zhD6F1Tz/9NHFxccTFxTFu3LhQ\neUaPyt0ZNWoUTZs2pWfPnpl6Qb/97W9p2rQpCQkJhfKDyIz07Rn/zp8/n169eoXWjxo1ikmTJgG5\np46fNGkSo0aNYsWKFfzmN79h9uzZtGjRgkOHDvH6668THx9PXFwc999/f6Zzffjhh0lMTGThwoXU\nq1eP3/3ud7Rv3542bdqwfPlyunfvziWXXMKECRMAQqnyy5cvT9WqVSM+d5GSLpo9k8uBDe6+EcDM\npgB9gbVh2zQFMnKvzwNmRLE9eRq/fDyH0w9nKjucfpjxy8dH1DuJVgr6YcOGERMTw4ABA3jooYdO\nmhBx8eLFrFmzhrPOOou2bdvSs2dPzIyJEyeyaNEi3J3ExEQ6d+5My5YtQ/tNnz6ddevWsXr1an74\n4QeaNm3KLbfcwq5du5g+fTpff/01ZpZjCvqCnldG+vb8pnHPKXV8hhYtWjBmzBiWLl3Ks88+S2pq\nKvfffz/Lli2jWrVqdOvWjRkzZtCvXz8OHDhAXFxcpiSRdevWZeHChYwePZrk5GQ+++wzDh8+HHq6\nZd26dUMZhk+WkFOkNIhmMKkNbA57vwVIzLLNSmAAgaGw/kAVMzvX3XcCsWa2FEgDnnD3bIHGzEYA\nI4CIh46+P/B9gcrzKxop6CdPnkzt2rXZt28fAwYM4B//+Ac333xznvtcffXVnHvuuUAg5fqnn36K\nmdG/f38qVaoUKl+wYEGmYPLJJ5+E0tTXqlWLK6+8Egg8oCs2Npbhw4fTs2fPTD2IUz2vgsopdXxu\nlixZQlJSUqjXM2TIED755BP69esXCsrhMobK4uPj2b9/P1WqVKFKlSrExsayZ8+ePJ/yKFIaRXMC\nPqc/lbMmArsX6GxmXwCdga0EggfARcF8Mb8AxplZtvEhd3/R3du4e5tIn3B3YaULC1SeX9FIQV+7\ndm0gkBn3F7/4BYsXLz5pOwo7BX3ZsmVZvHgxAwYMYMaMGVxzzTXZtjnV1Prhx8hIJAlkShsPOaeO\nz01e5xobG5ttniSj7jJlyoSWM96f7FgipVE0g8kWoG7Y+zpAavgG7p7q7te5e0vgwWDZ3ox1wX83\nAvOBlkTR3a3uJjYmNlNZbEwsd7e6O+K6CzMFfVpaGjt27ADg2LFjvPvuu6FH7E6fPp0HHnggxzZ8\n+OGH7Nq1i0OHDjFjxgw6duxIp06dmDFjBgcPHuTAgQNMnz4928OlOnXqxJQpU0hPT2fbtm3MmzcP\nCKTC37t3Lz169GDcuHE59kAKcl45ufjii1m7di1Hjhxh7969zJkzJ1/75SQxMZGPP/6YHTt2kJ6e\nzuuvv07nzp1PuT4RySyaw1xLgIZmVp9Aj2MQgV5GiJnVAHa5+3HgAQJ3dmFm1YCD7n4kuE1H4C9R\nbGtoXiRad3MVVgr6I0eO0L17d44dO0Z6ejpXXXUVt912GwDffPNN6PnwWf3sZz/jpptuYsOGDfzi\nF78I3QmWnJwcSu0+fPjwTENcAP3792fu3LnEx8fTqFGj0Bfwvn376Nu3L4cPH8bdC+UZ8FnVrVuX\nn//85yQkJNCwYcNsbSuImjVr8qc//YkuXbrg7vTo0eOU/xuISHZRTUFvZj2AcQRuDX7F3R83szHA\nUnefaWYDCdzB5cAnwB3BANIB+BtwnEDvaZy75/lIO6WghxtvvJGxY8eSdchv0qRJoYloKX5K2+dU\nipcSkYLe3WcDs7OUPRy2PA3I9gs4d/8ciI9m285E//u//1vUTRCRUkop6EuB5ORk/UpbRKJK6VRE\nRCRiCiYiIhIxBRMREYmYgomIiERMwSTKlII+/06Wgj782MOHD2ft2rU5bgeB26FTU1NzXV/YkpOT\nmT9/PklJSWzatOm0HVekuNDdXGH2vvMOP44dR9q2bZStWZPzR99D1d69C6VupaAvXOFJHXMyadIk\n4uLiqFWr1mlqkUjppp5J0N533mHb7x8mLTUV3ElLTWXb7x9m7zvvRFy3UtDnT9YU9HkdOykpiaVL\nl5Kenk5ycjJxcXHEx8czduxYpk2bxtKlSxkyZEgo/fyYMWNo27YtcXFxjBgxIpSrKykpifvvv5/L\nL7+cRo0ahR6ilZ6ezr333kt8fDwJCQn89a9/BWDZsmV07tyZ1q1b0717d7Zt2wZA1apVKV++PNWr\nV9fzUKR0cvcz4tW6dWvPau3atdnKcrO+y5W+tnGTbK/1Xa7Mdx05KVu2rFerVs1XrlyZ6zZz5871\n5s2bZ3u1b98+x+07d+7scXFx3rx5cx8zZowfP348zzZMnDjRL7zwQt+xY4cfPHjQmzVr5kuWLPGl\nS5d6XFyc79+/3/ft2+dNmzb15cuXu7t7pUqV3N39X//6l1911VWelpbmW7du9apVq/qbb77pO3fu\n9EaNGoWOvXv37ojPK6vcjp1xDTLO4aqrrgrtk9GOjPUZdu7cGVq+8cYbfebMmaHtfvWrX7m7+6xZ\ns7xr167u7v7888/7dddd58eOHQvtf/ToUW/fvr3/+OOP7u4+ZcoUHzZsWL7OJS8F+ZyKFDYCGUki\n/g7WMFdQWvAvzPyW55dS0J96Cvrcjh2uQYMGbNy4kTvvvJOePXvSrVu3HOuaN28ef/nLXzh48CC7\ndu2iWbNm9A4OYYanss+Y7/joo48YOXIkZcsG/hepXr06a9asYc2aNVx99dVAoPdSs2bNUz4/kTOJ\nhrmCyubypZBbeX4pBf2pp6DP7djhqlWrxsqVK0lKSuK5555j+PDh2bY5fPgwv/zlL5k2bRqrV6/m\ntttuy5TOPqdU9u6e7djuTrNmzULZj1evXs0HH3yQ73MROZMpmASdP/oeLDZzCnqLjeX80fdEXLdS\n0J9aCvrcjh1ux44dHD9+nAEDBvDoo4+yfPlyIBBo9+3bB5x4DkqNGjXYv39/vu5G69atGxMmTAgF\nl127dtG4cWO2b9/OwoULgcD1//LLL/N1LiJnOg1zBWXctRWtu7mUgr7gcjt2uK1btzJs2LDQQ7T+\n9Kc/hc5r5MiRVKxYkYULF3LbbbcRHx9PvXr1aNu27UmPPXz4cNavX09CQgLlypXjtttuY9SoUUyb\nNo277rqLvXv3kpaWxj333EOzZs0K98RFSqCopqA/nZSCXinoS6rS9jmV4qVEpKCX00sp6EWkqCiY\nlAJKQS8i0aYJeBERiZiCiYiIREzBREREIqZgIiIiEVMwibJopKB/8MEHqVu3bqa6IfAblBtuuIFL\nL72UxMTEqKRCzy31+6RJkxg1alShHw8KJ717amoqAwcODL0fPHgwCQkJUfl9zMlS6YuciXQ3V5j1\ni75n4dvfsH/XESpXr0D7vpfQKPHCQqm7MFPQ9+7dm1GjRtGwYcNM5S+//DLVqlVjw4YNTJkyhfvv\nv5833ngjomNldbLU78VVrVq1Qr98//777/n888/573//m+/909LSQnm6RCQ79UyC1i/6nnmTv2b/\nriMA7N91hHmTv2b9ou8jrruwU9C3a9cuxwSDb7/9NkOHDgVg4MCBzJkzJ8/8W5s2baJJkyYMHTqU\nhIQEBg4cyMGDB4FA8GvZsiXx8fHccsstHDkSuC4Zqd8BJk6cGPpl+meffRaq98033yQuLo7mzZvT\nqVOniM83p/Tu4b2yadOmhW59Tk5O5q677qJDhw40aNAgFEA2bdoUSjvTrVs3fvzxR1q0aMGCBQtY\nsWIF7dq1IyEhgf79+7N79+7Quf7ud7+jc+fOjB8/nuTkZG6//Xa6dOlCgwYN+Pjjj7nlllu47LLL\nMt16nTWVvkhpoGAStPDtb0g7ejxTWdrR4yx8+5uI6j1y5Ah9+/ZlxowZNGnSJMdtCiMhIgRSi9St\nWxcIJGKsWrUqO3fuzHOfdevWMWLECFatWsXZZ5/N888/z+HDh0lOTuaNN95g9erVpKWl8cILL2Ta\nb9u2bTzyyCN89tlnfPjhh5mGvsaMGcP777/PypUrmTlzZrZj7tu3L8fzbdGiRY5DaOPHj6dDhw68\n9dZbofPLy7Zt2/j000959913+e1vf5tt/cyZM7nkkktYsWIFV1xxBTfffDN//vOfWbVqFfHx8Zme\n97Jnzx4+/vhjfv3rXwOwe/du5s6dy9ixY+nduzejR4/myy+/ZPXq1aH8ZEuWLMn0r0hpoH57UEaP\nJL/l+RWNFPS5yakXcrKsu3Xr1qVjx45AIB3LM888w9VXX039+vVp1KgRAEOHDuW5557jnntOJL1c\ntGgRSUlJob++b7jhBtavXw9Ax44dSU5O5uc//3kovXu4KlWqFMr55qZfv36UKVOGpk2b8sMPP+S5\n7d69e9mzZ08o79fQoUO5/vrrQ+tvuOGGTNv37t0bMyM+Pp4LLriA+Ph4AJo1a8amTZto0aJFIZ+N\nSMmgYBJUuXqFHANH5eoVIqo3IwX9VVddxR//+Ed+97vfZdtm3rx5jB49Olv5WWedVaDH59apU4fN\nmzdTp04d0tLS2Lt3L9WrV89zn8JOTQ8wYcIEFi1axKxZs2jRogUrVqwIPUsFAj2TrNmJM/zzn/+k\nadOmBTp2eDp5OJFSHnIOsAWR8ayXrHWXKVMm03HKlCkTyjAsUhopmAS173sJ8yZ/nWmoq2z5MrTv\nG/kcR0YK+iuuuIILLriAW2+9NdP6wuqZ9OnTh1dffZX27dszbdo0rrzySsyMrVu3cvPNNzNnzpxs\n+3z33XcsXLiQ9u3b8/rrr/Ozn/2MJk2asGnTJjZs2MCll17KP/7xj2wZexMTE7n77rvZuXMnZ599\nNm+++SbNmzcHAtmLExMTSUxM5J133mHz5s2Zgklh9EwuuOACvvrqKxo3bsz06dOpUqXKKdVTtWpV\nqlWrxoIFC7jiiityPFcROTkFk6CMu7aidTdXYaWgB/jNb37DP//5Tw4ePEidOnUYPnw4KSkp3Hrr\nrdx0001ceumlVK9enSlTpgCBOYTc7kS67LLLePXVV/mf//kfGjZsyO23305sbCwTJ07k+uuvJy0t\njbZt2zJy5MhM+9WsWZOUlBTat29PzZo1adWqFenp6QDcd999/Oc//8Hd6dq1ayjIFKYnnniCXr16\nUbduXeLi4ti/f/8p1/Xqq68ycuRIDh48SIMGDZg4cWIhtlSkdFAK+lLg2Wef5aKLLqJPnz6Zyjdt\n2kSvXr1Ys2ZNEbVMQJ9TKVpKQS/5Fq0fE4qIZNCtwaVYvXr11CsRkUKhYCIiIhFTMBERkYgpmIiI\nSMSiGkzM7BozW2dmG8wsW14LM7vYzOaY2Sozm29mdcLWDTWz/wRfQ6PZThERiUzUgomZxQDPAdcC\nTYHBZpb1p81PAa+5ewIwBvhTcN/qwCNAInA58IiZVYtWW6NJKegjd7IU9OHHnjBhAq+99lqudc2f\nP79AWQUiNWnSJFJSUkhJSWHSpEmn7bgip1s0bw2+HNjg7hsBzGwK0BcI/yZqCmTkEZkHzAgudwc+\ndPddwX0/BK4BXo9ie/lqwTwWTHmNfTt3UOXcGlwx6GYuu6JLodStFPSnR9YfV2Y1f/58KleuXOAk\nmiKSt2gOc9UGNoe93xIsC7cSGBBc7g9UMbNz87kvZjbCzJaa2dLt27dH1NivFszjgxefZd+O7eDO\nvh3b+eDFZ/lqwbyI6gWloI9UTinoczt2SkoKTz31FADPPPMMTZs2JSEhgUGDBrFp0yYmTJjA2LFj\nQ+nn33nnHRITE2nZsiVXXXVVKDFkSkoKt9xyC0lJSTRo0IBnnnkmdIzXXnuNhIQEmjdvzk033QTA\n9u3bGTBgAG3btqVt27ahNlWsWJHKlStTuXJlKlasGPG1ECm23D0qL+B64O9h728C/pplm1rAW8AX\nwHgCQaMqcB/wUNh2vwd+ndfxWrdu7VmtXbs2W1lu/vbLZH/q5z2zvf72y+R815GTsmXLerVq1Xzl\nypW5bjN37lxv3rx5tlf79u3zrLtSpUqZ3jdr1sw3b94cet+gQQPfvn17rvt/++23Dvinn37q7u7D\nhg3zJ5980g8dOuR16tTxdevWubv7TTfd5GPHjnV3986dO/uSJUs8NTXV69at6z/++KMfOXLEO3To\n4HfccYe7u8fFxfmWLVvc3X337t3ZjvvTTz/leL7Nmzf3L7/8Ms9zdvc8j/3II4/4k08+6e7uNWvW\n9MOHD2dqR/h6d/ddu3b58ePH3d39pZde8l/96leh7dq3b++HDx/27du3e/Xq1f3o0aO+Zs0ab9So\nUei67ty5093dBw8e7AsWLHB39//+97/epEmTk55HhoJ8TkUKG7DUC+E7P5rDXFuA8IdP1AFSwzdw\n91TgOgAzqwwMcPe9ZrYFSMprKV9SAAAUu0lEQVSy7/wotpV9O3cUqDy/lIK+8FPQ53XscAkJCQwZ\nMoR+/frRr1+/HOvasmULN9xwA9u2bePo0aPUr18/tK5nz55UqFCBChUqcP755/PDDz8wd+5cBg4c\nSI0aNQBCWZk/+uijTHNJP/30E/v27TvlBJQiJc1Jh7nM7Cwz+72ZvRR839DMeuWj7iVAQzOrb2bl\ngUFApiclmVkNM8towwPAK8Hl94FuZlYtOPHeLVgWNVXOrVGg8vzKSEG/ZMkS/vjHP+a4TWE9HCsj\nBT1Q5CnoH3vsMTZv3kyLFi2yPaCroA/HKsixw82aNYs77riDZcuW0bp16xxTxN95552MGjWK1atX\n87e//S1TOvvwFPMxMTGkpaXh7jke+/jx4yxcuJAVK1awYsUKtm7dqkAipUp+5kwmAkeA9sH3W4DH\nTraTu6cBowgEga+Aqe7+pZmNMbOMjINJwDozWw9cADwe3HcX8CiBgLQEGBMsi5orBt1M2fKZn11S\ntnwFrhh0c8R1Z6Sgnzx5Mi+//HK29Rk9k6yvgt51lJGCHsiWgr5r16457pORgh7IMQU9kGsK+vnz\n57Nz506OHTvGm2++GVqXkYJ+zJgx1KhRIxTgMmT0THJ65edZJnkdO8Px48fZvHkzXbp04S9/+Qt7\n9uxh//79VKlShX379oW227t3L7VrB6bjMq5dXrp27crUqVNDAXLXrsDHslu3bjz77LOh7aL58C+R\n4ig/w1yXuPsNZjYYwN0PWX7+LAxsOxuYnaXs4bDlacC0XPZ9hRM9lajLuGsrWndzKQV94cnr2BnS\n09O58cYb2bt3L+7O6NGjOeecc+jduzcDBw7k7bff5q9//SspKSlcf/311K5dm3bt2vHtt9/meexm\nzZrx4IMP0rlzZ2JiYmjZsiWTJk3imWee4Y477iAhIYG0tDQ6derEhAkTCvW8RYqzk6agN7PPga7A\nZ+7eyswuAV5398tPRwPzSynoc6cU9MWbPqdSlE5nCvpHgPeAumY2GegIJEd6YDl9lIJeRKItz2AS\nHM76msAdV+0AA+5298hucZJiQSnoRaSw5BlM3N3NbIa7twZmnaY2Farc7r4RKQ7ye+ecSHGXn7u5\n/m1mbaPekiiIjY1l586d+h9WiiV3Z+fOncTGxhZ1U0Qilp85ky7A/5jZf4EDBIa63APJGYu1OnXq\nsGXLFiJNtSISLbGxsdSpU+fkG4oUc/kJJtdGvRVRUq5cuUy/aBYRkeg46TCXu/8XOAfoHXydEywT\nEREB8pdO5W5gMnB+8PW/ZnZntBsmIiIlR36GuW4FEt39AICZ/RlYCPw1mg0TEZGSIz93cxkQnqsi\nPVgmIiIC5K9nMhFYZGbTg+/7AdmzFYqISKl10mDi7k+b2XzgZwR6JMPc/YtoN0xEREqOkwYTM2sH\nfOnuy4Pvq5hZorsvinrrRESkRMjPnMkLwP6w9weCZSIiIkA+J+A9LB+Jux8nf3MtIiJSSuQnmGw0\ns7vMrFzwdTewMdoNExGRkiM/wWQk0AHYGnwlAiOi2SgRESlZ8nM314/AoNPQFhERKaFy7ZmY2W1m\n1jC4bGb2ipntNbNVZtbq9DVRRESKu7yGue4GNgWXBwPNgQbAr4Dx0W2WiIiUJHkFkzR3PxZc7gW8\n5u473f0joFL0myYiIiVFXsHkuJnVNLNYoCvwUdi6itFtloiIlCR5TcA/DCwFYoCZ7v4lgJl1RrcG\ni4hImFyDibu/a2YXA1XcfXfYqqXADVFvmYiIlBh53hrs7mnA7ixlB6LaIhERKXHy86NFERGRPCmY\niIhIxE4pmJhZk8JuiIiIlFyn2jP5oFBbISIiJVquE/Bm9kxuq4BzotMcEREpifK6m2sY8GvgSA7r\nBkenOSIiUhLlFUyWAGvc/fOsK8wsJWotEhGREievYDIQOJzTCnevH53miIhISZTXBHxldz942loi\nIiIlVl7BZEbGgpn961QqN7NrzGydmW0ws9/msP4iM5tnZl8En5PSI1hez8wOmdmK4GvCqRxfRERO\nj7yGuSxsuUFBKzazGOA54GpgC7DEzGa6+9qwzR4Cprr7C2bWFJgN1Auu+8bdWxT0uCIicvrl1TPx\nXJbz63Jgg7tvdPejwBSgbw7HODu4XBVIPYXjiIhIEcurZ9LczH4i0EOpGFwm+N7d/ezcdwWgNrA5\n7P0WIDHLNinAB2Z2J4EHbl0Vtq6+mX0B/AQ85O4Lsh7AzEYAIwAuuuiikzRHRESiJdeeibvHuPvZ\n7l7F3csGlzPenyyQQOZhslC1Wd4PBia5ex2gB/APMysDbAMucveWBB4T/E8zy3ZMd3/R3du4e5vz\nzjsvH00SEZFoiGaixy1A3bD3dcg+jHUrMBXA3RcCsUANdz/i7juD5cuAb4BGUWyriIhEIJrBZAnQ\n0Mzqm1l5YBAwM8s23xF4JDBmdhmBYLLdzM4LTuBjZg2AhujpjiIixVaeD8eKhLunmdko4H0Cj/59\nxd2/NLMxwFJ3n0kgXctLZjaawBBYsru7mXUCxphZGpAOjHT3XdFqq4iIRMbcT+VGreKnTZs2vnTp\n0qJuhohIiWJmy9y9TaT16OFYIiISMQUTERGJmIKJiIhETMFEREQipmAiIiIRUzAREZGIKZiIiEjE\nFExERCRiCiZy+qyaCmPjIOWcwL+rphZ1i0SkkEQtnYpIJqumwjt3wbFDgfd7NwfeAyT8vOjaJSKF\nQsFEou6rBfNY8OIr7Dvamiplj3DF+Zu4rOr2QGCZM0bBROQMoGAiUfXVgnl88OKzpB0NfNT2pcXy\nwbaGAIGAsndLUTZPRAqJ5kwkqhZMeY20o0cylaV5DAt+rBd4U7XO6W+UiBQ69UykUO195x1+HDuO\ntG3bKFuzJvvOq5jjdvvSKkC5itD14dPcQhGJBvVMpNDsfecdtv3+YdJSU8GdtNRUKh5Ly3HbKuXT\nofczmi8ROUMomEih+XHsOPzw4UxljVJ3EpPlmTlly1fgihH3K5CInEE0zCWFJm3btmxltffsB4ON\nreLYt3MHVc6twRWDbuayK7oUQQtFJFoUTKTQlK1ZMzDElcXFFc/mqucmFkGLROR00TCXFNiML7bS\n8Ym51P/tLDo+MZcZX2wF4PzR92CxsZm2tdhYzh99T1E0U0ROI/VMpEBmfLGVB95azaFj6QBs3XOI\nB95aDUC/3r0BMt3Ndf7oe6gaLBeRM5eCiRTIk++vCwWSDIeOpfPk++vo17I2VXv3VvAQKYU0zCUF\nkrrnUIHKRaR0UDCRAql1Ts4/QsytXERKBwUTKZD7ujemYrmYTGUVy8VwX/fGRdQiESkONGciBdKv\nZW0gMHeSuucQtc6pyH3dG4fKRaR0UjCRAuvXsraCh4hkomEuERGJmIKJiIhETMGklJq1cRbdpnUj\n4dUEuk3rxqyNs4q6SSJSgmnOpBSatXEWKZ+ncDg9kOF324FtpHyeAkDPBj2LsGUiUlKpZ1IKjV8+\nPhRIMhxOP8z45eOLqEUiUtIpmJRC3x/4vkDlIiIno2BSCl1Y6cIClYuInIyCSSl0d6u7iY3JnCo+\nNiaWu1vdXUQtEpGSLqrBxMyuMbN1ZrbBzH6bw/qLzGyemX1hZqvMrEfYugeC+60zs+7RbGdp07NB\nT1I6pFCzUk0Mo2almqR0SNHku4icMvMsz+cutIrNYoD1wNXAFmAJMNjd14Zt8yLwhbu/YGZNgdnu\nXi+4/DpwOVAL+Aho5O7pWY+ToU2bNr506dKonIuIyJnKzJa5e5tI64lmz+RyYIO7b3T3o8AUoG+W\nbRw4O7hcFch45mtfYIq7H3H3b4ENwfpERKQYimYwqQ1sDnu/JVgWLgW40cy2ALOBOwuwL2Y2wsyW\nmtnS7du3F1a7RUSkgKIZTCyHsqxjaoOBSe5eB+gB/MPMyuRzX9z9RXdv4+5tzjvvvIgbLCIipyaa\nv4DfAtQNe1+HE8NYGW4FrgFw94VmFgvUyOe+IiJSTESzZ7IEaGhm9c2sPDAImJllm++ArgBmdhkQ\nC2wPbjfIzCqYWX2gIbA4im0VEZEIRK1n4u5pZjYKeB+IAV5x9y/NbAyw1N1nAr8GXjKz0QSGsZI9\ncHvZl2Y2FVgLpAF35HUnl4iIFK2o3Rp8uunWYBGRgisJtwaLiEgpoWAiIiIRUzAREZGIKZiIiEjE\nFExERCRiCiYiIhIxBRMREYmYgomIiEQsmrm55CTWL/qehW9/w/5dR6hcvQLt+15Co0Q9OldESh4F\nkyKyftH3zJv8NWlHjwOwf9cR5k3+GkABRURKHA1zFZGFb38TCiQZ0o4eZ+Hb3xRRi0RETp2CSRHZ\nv+tIgcpFRIozBZMiUrl6hQKVi4gUZwomRaR930soWz7z5S9bvgzt+15SRC0SETl1moAvIhmT7Lqb\nS0TOBAomRahR4oUKHiJyRtAwl4iIREzBREREIqZgIiIiEVMwERGRiCmYiIhIxBRMREQkYgomIiIS\nMQUTERGJmIKJiIhETMFEREQipmAiIiIRUzAREZGIKZiIiEjEFExERCRiCiYiIhIxBRMREYmYgomI\niERMwURERCKmYCIiIhGLajAxs2vMbJ2ZbTCz3+awfqyZrQi+1pvZnrB16WHrZkaznSIiEpmy0arY\nzGKA54CrgS3AEjOb6e5rM7Zx99Fh298JtAyr4pC7t4hW+0REpPBEs2dyObDB3Te6+1FgCtA3j+0H\nA69HsT0iIhIlUeuZALWBzWHvtwCJOW1oZhcD9YG5YcWxZrYUSAOecPcZOew3AhgRfHvEzNYURsPP\nADWAHUXdiGJC1+IEXYsTdC1OaFwYlUQzmFgOZZ7LtoOAae6eHlZ2kbunmlkDYK6ZrXb3bzJV5v4i\n8CKAmS119zaF0fCSTtfiBF2LE3QtTtC1OCH4R3vEojnMtQWoG/a+DpCay7aDyDLE5e6pwX83AvPJ\nPJ8iIiLFSDSDyRKgoZnVN7PyBAJGtruyzKwxUA1YGFZWzcwqBJdrAB2BtVn3FRGR4iFqw1zunmZm\no4D3gRjgFXf/0szGAEvdPSOwDAamuHv4ENhlwN/M7DiBgPdE+F1guXixkE+hJNO1OEHX4gRdixN0\nLU4olGthmb/DRURECk6/gBcRkYgpmIiISMRKRDBRWpYT8nEtLjKzeWb2hZmtMrMeYeseCO63zsy6\nn96WF75TvRZmVs/MDoV9Liac/tYXrnxci4vNbE7wOsw3szph64aa2X+Cr6Gnt+WFL8JrccZ8X5jZ\nK2b2Y26/v7OAZ4LXaZWZtQpbV/DPhLsX6xeByftvgAZAeWAl0DSP7e8kMNmf8X5/UZ/D6bwWBCbT\nbg8uNwU2hS2vBCoQ+IHoN0BMUZ9TEV2LesCaoj6H03wt3gSGBpevBP4RXK4ObAz+Wy24XK2oz6ko\nrkXw/Zn0fdEJaJXbZx3oAfwfgd8EtgMWRfKZKAk9E6VlOSE/18KBs4PLVTnx256+BO6aO+Lu3wIb\ngvWVVJFcizNNfq5FU2BOcHle2PruwIfuvsvddwMfAtechjZHSyTX4ozi7p8Au/LYpC/wmgf8GzjH\nzGpyip+JkhBMckrLUjunDfNKy2Jm/zazftFr5mmRn2uRAtxoZluA2QR6avndtySJ5FoA1A8Of31s\nZldEtaXRl59rsRIYEFzuD1Qxs3PzuW9JEsm1gDPr++JkcrtWp/SZKAnBpDDSsrQBfgGMM7NLCruB\np1F+rsVgYJK71yHQjf2HmZXJ574lSSTXYhuBz0VL4FfAP83sbEqu/FyLe4HOZvYF0BnYSiDvXWn8\nXOR2LeDM+r44mdyu1Sl9JkpCMFFalhPycy1uBaYCuPtCIJZAUruCXMeS4JSvRXCob2ewfBmBMfZG\nUW9x9Jz0Wrh7qrtfFwygDwbL9uZn3xImkmtxpn1fnExu1+rUPhNFPUmUj0mksgQmgOpzYkKtWQ7b\nNQY2EfwhZrCsGlAhuFwD+A95TN4X91d+rgWBCbXk4PJlwQ+BAc3IPAG/kZI9AR/JtTgv49wJTNRu\nBaoX9TlF+VrUAMoElx8HxgSXqwPfBv9fqRZcLq3X4oz6vgieRz1yn4DvSeYJ+MWRfCaK/GTzeUF6\nAOsJ/AX5YLBsDNAnbJsUAmlXwvfrAKwOfqBWA7cW9blE+1oQmFz8LHjOK4BuYfs+GNxvHXBtUZ9L\nUV0LAuPlXwbLlwO9i/pcTsO1GBj8clwP/D3jSzO47hYCN2RsAIYV9bkU1bU4074vCIzSbAOOEeht\n3AqMBEYG1xuBBxh+EzzfNpF8JpRORUREIlYS5kxERKSYUzAREZGIKZiIiEjEFExERCRiCiYiIhIx\nBRORLMysv5m5mTUp6raIlBQKJiLZDQY+JZBRISrMLCZadYsUBQUTkTBmVhnoSOAHXoPCyn9jZqvN\nbKWZPREsu9TMPgqWLTezS8wsyczeDdvvWTNLDi5vMrOHzexT4Hozu83MlgT3/5eZnRXc7gIzmx4s\nX2lmHczsUTO7O6zex83srtNyUUTyoWxRN0CkmOkHvOfu681sV/CBQRcEyxPd/aCZVQ9uO5lA1oXp\nZhZL4I+zujlXG3LY3X8GYGbnuvtLweXHCASwvwLPAB+7e/9gD6YygVQwbwHjg8kqB1GyHyEgZxgF\nE5HMBgPjgstTgu/LABPd/SCAu+8ysypAbXefHiw7DGCWU8LVTN4IW44LBpFzCASM94PlVwI3B+tN\nB/YCe81sp5m1JBDcvvBgskqR4kDBRCQo+EyLKwl8yTuBp/Y58C+yp+DOLWqkkXn4ODbL+gNhy5OA\nfu6+MjgUlnSSJv4dSAYuBF45ybYip5XmTEROGEjgyXMXu3s9d69LIGPqLuCWsDmN6u7+E7Al4wFK\nZlYhuP6/QNPg+6pA1zyOVwXYZmblgCFh5XOA24P1xoQ9a2U6gSfeteVEL0akWFAwETlhMIEv7HD/\nAmoBM4GlZraCwMOVAG4C7jKzVcDnwIXuvpnAM1RWEZhT+SKP4/0eWETgsahfh5XfDXQxs9XAMgKP\nD8ADj6GdB0z1zA+AEylyyhosUkIEJ96XA9e7+3+Kuj0i4dQzESkBzKwpgWdLzFEgkeJIPRMREYmY\neiYiIhIxBRMREYmYgomIiERMwURERCKmYCIiIhH7fw2rwfwMy6vCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, label in zip(range(0, 3), (3, 5, 10)):\n",
    "    plt.plot(sKNN_acc_uniform[i], sKNN_f1_uniform[i], \"o\", label='K = {}, poids = \"uniform\"'.format(label))\n",
    "    plt.plot(sKNN_acc_distance[i], sKNN_f1_distance[i], \"o\", label='K = {}, poids = \"distance\"'.format(label))\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim([0.75, 1])\n",
    "plt.ylim([0.75, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN - Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après le graphique des Accuracy et F1 scores, on se rend compte que l'hyperparamètre `K` pour Spam est `K = 3` La validation croisée sera donc effectuée avec l'hyperparamètre `K = 3` et `poids = distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8029222185756482\n"
     ]
    }
   ],
   "source": [
    "fold = 10\n",
    "clf = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "sKNN_scores = cross_val_score(clf, X_mail, Y_mail, cv= K)\n",
    "print(sum(sKNN_scores)/K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Naive\n",
    "#### Distribution Gaussienne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hold-out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision : 0.8387681159420289\n",
      "Score F1 : 0.8402037805334562\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(Xm_train, Ym_train)\n",
    "Y_pred = clf.predict(Xm_test)\n",
    "\n",
    "sgauss_acc = accuracy_score(Ym_test, Y_pred)\n",
    "sgauss_f1 = f1_score(Ym_test, Y_pred, average='weighted') \n",
    "\n",
    "print(\"Précision : {}\".format(sgauss_acc))\n",
    "print(\"Score F1 : {}\".format(sgauss_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8122848703642929\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "clf = GaussianNB()\n",
    "scores = cross_val_score(clf, X_mail, Y_mail, cv=K)\n",
    "print(sum(scores)/K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution  Multinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision : 0.907608695652174\n",
      "Score F1 : 0.9081476031094811\n"
     ]
    }
   ],
   "source": [
    "est = KBinsDiscretizer(n_bins = 10, encode='ordinal')\n",
    "est.fit(X_mail) \n",
    "Xt_mail = est.transform(X_mail)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "Xm_scaled = scaler.fit_transform(Xt_mail)\n",
    "\n",
    "Xm_train, Xm_test, Ym_train, Ym_test = train_test_split(Xm_scaled, Y_mail, test_size=0.20, random_state=42, stratify=Y_mail)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(Xm_train, Ym_train)\n",
    "Y_pred = clf.predict(Xm_test)\n",
    "\n",
    "smulti_acc = accuracy_score(Ym_test, Y_pred)\n",
    "smulti_f1 = f1_score(Ym_test, Y_pred, average='weighted') \n",
    "\n",
    "print(\"Précision : {}\".format(smulti_acc))\n",
    "print(\"Score F1 : {}\".format(smulti_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8804200853298326\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "clf = MultinomialNB()\n",
    "smulti_scores = cross_val_score(clf, Xm_scaled, Y_mail, cv= K)\n",
    "print(sum(smulti_scores)/K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forêts aléatoires (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [3, 5, 10, 20, 30, 40, 50, 100], 'n_estimators': [10, 20, 30, 40, 50, 100, 200, 300]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3,5,10,20,30,40,50,100],\n",
    "    'n_estimators': [10,20,30,40,50,100,200,300]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator =  RandomForestClassifier(), param_grid = param_grid, cv = 10, n_jobs = -1, verbose = 0)\n",
    "grid_search.fit(Xm_train, Ym_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision : 0.9528985507246377\n",
      "Score F1 : 0.9527038522735986\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'],max_depth=grid_search.best_params_['max_depth'])\n",
    "clf.fit(Xm_train,Ym_train)\n",
    "Y_pred = clf.predict(Xm_test)\n",
    "srandfor_acc = accuracy_score(Ym_test, Y_pred)\n",
    "srandfor_f1 = f1_score(Ym_test, Y_pred, average='weighted') \n",
    "print(\"Précision : {}\".format(srandfor_acc))\n",
    "print(\"Score F1 : {}\".format(srandfor_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation croisée pour les forêts aléatoires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9384370015948964\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, Xm_test, Ym_test, cv= K)\n",
    "print(sum(scores)/K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de galaxies\n",
    "\n",
    "Nous n'avons pas utilisé la recherche par grille pour les données Spam, mais nous allons l'utiliser ici pour définir les meilleurs hyperparamètres pour l'algorithme des K-plus proches voisins. Nous aurions pu l'utiliser dans les cas précédents mais cela ne change rien en terme de résultats purs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_vectors = pd.read_csv('galaxy_feature_vectors.csv', delimiter = ',', header=None)\n",
    "labels = pd.read_csv('galaxy_label_data_set.csv', delimiter = ',')\n",
    "X_galaxy = pd.read_csv('galaxy_feature_vectors.csv', delimiter = ',', header=None).values[:,0:-1]\n",
    "Y_galaxy = pd.read_csv('galaxy_feature_vectors.csv', delimiter = ',', header=None).values[:,-1:].astype(int).flatten()\n",
    "Xg_train, Xg_test, Yg_train, Yg_test = train_test_split(X_galaxy, Y_galaxy, test_size=0.20, random_state=42, stratify=Y_galaxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nous utilisons les caractéristiques du TP1 dans le vecteur d'entrée, combinées aux caractéristiques de galaxy_feature_vectors données par le TP2. (qu'est ce qui garantit que l'ordre des observations de galaxy_feature_vectors.csv soit le même que celles du TP1 ? )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_galaxy_TP1 = pd.read_csv('vectors_TP1.csv', delimiter = ',').values[:,0:2]\n",
    "# utilisons uniquement circularite et aspect ratio ratio\n",
    "X_galaxy_TP1_1= np.concatenate([X_galaxy,X_galaxy_TP1[:,0:2]],axis=1)\n",
    "Xgtp1_train, Xgtp1_test, Ygtp1_train, Ygtp1_test = train_test_split(X_galaxy_TP1_1, Y_galaxy, test_size=0.20, random_state=42, stratify=Y_galaxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons une incohérence dans les classes de sortie entre `galaxy_feature_vectors.csv` et `galaxy_label_data_set.csv` comme montré ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "galaxy_feature_vectors\n",
      "0    1.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    1.0\n",
      "Name: 75, dtype: float64\n",
      "galaxy_label_data_set\n",
      "       id   class\n",
      "0  100090  smooth\n",
      "1  100134  spiral\n",
      "2  100322  spiral\n",
      "3  100380  spiral\n",
      "4  100458  smooth\n",
      "5  100479  smooth\n"
     ]
    }
   ],
   "source": [
    "print(\"galaxy_feature_vectors\")\n",
    "print(pd.read_csv('galaxy_feature_vectors.csv', delimiter = ',', header=None)[75].head(6))\n",
    "\n",
    "print(\"galaxy_label_data_set\")\n",
    "print(labels.head(6)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En effet, dans `galaxy_feature_vectors`, la classe 1 correspond à $smooth$ alors que la classe 0 correspond à $spiral$. Cependant, dans `galaxy_label_data_set`, les classes ne correspondent pas à `galaxy_feature_vectors`. Nous avons donc choisi de ne pas utiliser nos primitives trouvées dans le TP1 dans nos analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gKNN_acc_uniform = []\n",
    "gKNN_f1_uniform = []\n",
    "\n",
    "gKNN_acc_distance = []\n",
    "gKNN_f1_distance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 10, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'weights':('uniform', 'distance'), 'n_neighbors':[3, 5, 10]}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(knn, parameters, cv=10)\n",
    "clf.fit(X_galaxy, Y_galaxy)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K = 3, 5, 10, Poids = 'uniform' & Poids = 'distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n_neigh in (3, 5, 10):\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neigh, weights='uniform')\n",
    "\n",
    "    clf = clf.fit(Xg_train, Yg_train)\n",
    "    Y_pred = clf.predict(Xg_test)\n",
    "\n",
    "    acc = accuracy_score(Yg_test, Y_pred)\n",
    "    f1 = f1_score(Yg_test, Y_pred, average='weighted') \n",
    "\n",
    "    gKNN_acc_uniform.append(acc)\n",
    "    gKNN_f1_uniform.append(f1)\n",
    "\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neigh, weights='distance')\n",
    "    clf = clf.fit(Xg_train, Yg_train)\n",
    "    Y_pred = clf.predict(Xg_test)\n",
    "\n",
    "    acc = accuracy_score(Yg_test, Y_pred)\n",
    "    f1 = f1_score(Yg_test, Y_pred, average='weighted') \n",
    "\n",
    "    gKNN_acc_distance.append(acc)\n",
    "    gKNN_f1_distance.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN - Accuracy & F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEKCAYAAADXdbjqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, label in zip(range(0, 3), (3, 5, 10)):\n",
    "    plt.plot(gKNN_acc_uniform[i], gKNN_f1_uniform[i], \"o\", label='K = {}, poids = \"uniform\"'.format(label))\n",
    "    plt.plot(gKNN_acc_distance[i], gKNN_f1_distance[i], \"o\", label='K = {}, poids = \"distance\"'.format(label))\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim([0.5, 0.6])\n",
    "plt.ylim([0.5, 0.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN - Cross-validation\n",
    "Les meilleurs hyperparamètres renvoyés par `Grid Search` sont `K = 10` et `poids = distance`. Cependant, lorsque nous exécutons les différentes commandes sans passer par la fonction, nous obtenons de meilleurs résultats lorsque `K = 10` et que le `poids = uniforme`. Nous allons donc faire la validation croisée avec les deux hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58865248 0.57446809 0.57362507 0.54405677 0.56771141 0.56002365\n",
      " 0.5556213  0.58047337 0.5556213  0.57159763]\n",
      "0.5671851089912532\n"
     ]
    }
   ],
   "source": [
    "nfold = 10\n",
    "clf = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "gKNN_scores = cross_val_score(clf, X_galaxy, Y_galaxy, cv=nfold)\n",
    "print (gKNN_scores)\n",
    "print(sum(gKNN_scores)/nfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58510638 0.57269504 0.56357185 0.5487877  0.56830278 0.5505618\n",
      " 0.57159763 0.57928994 0.56331361 0.5704142 ]\n",
      "0.5673640930790169\n"
     ]
    }
   ],
   "source": [
    "nfold = 10\n",
    "clf = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "scores = cross_val_score(clf, X_galaxy, Y_galaxy, cv=nfold)\n",
    "print (scores)\n",
    "print(sum(scores)/nfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons que la validation croisée pour `K = 10` et `poids = distance` donne, quoique d'une différence très minime, un meilleur résultat. Nous pouvons donc dire que l'utilisation de `Grid Search` pour la recherche des meilleurs hyperparamètres est tout de même meilleure qu'une recherche faite \"soi-même\" dans ce cas là."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes\n",
    "#### Loi Gaussienne (normale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision : 0.797752808988764\n",
      "Score F1 : 0.797131047668415\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(Xg_train, Yg_train)\n",
    "Y_pred = clf.predict(Xg_test)\n",
    "\n",
    "ggauss_acc = accuracy_score(Yg_test, Y_pred)\n",
    "ggauss_f1 = f1_score(Yg_test, Y_pred, average='weighted') \n",
    "\n",
    "print(\"Précision : {}\".format(ggauss_acc))\n",
    "print(\"Score F1 : {}\".format(ggauss_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loi Multinomiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est = KBinsDiscretizer(n_bins = 10, encode='ordinal')\n",
    "est.fit(X_galaxy) \n",
    "Xt_galaxy = est.transform(X_galaxy)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "Xg_scaled = scaler.fit_transform(Xt_galaxy)\n",
    "\n",
    "Xg_train, Xg_test, Yg_train, Yg_test = train_test_split(Xg_scaled, Y_galaxy, test_size=0.20, random_state=42, stratify=Y_galaxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recherche de l'hyperparamètre $alpha$ pour la loi multinomiale*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1578947368421053\n"
     ]
    }
   ],
   "source": [
    "NBParamGrid = dict(alpha=np.linspace(0,2,20)[1:])\n",
    "paramsearch = GridSearchCV(estimator=MultinomialNB(), param_grid=NBParamGrid, n_jobs=6,cv=10)\n",
    "paramsearch.fit(Xg_train, Yg_train)\n",
    "selected_alpha = paramsearch.best_estimator_.alpha\n",
    "print(selected_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La meilleure valeur de alpha est 1.158 d'après `Grid Search` et sera utilisée par la suite pour la validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes - Loi multinomiale - avec validation hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision : 0.7965700768775872\n",
      "Score F1 : 0.7965745650692521\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=selected_alpha)\n",
    "clf.fit(Xg_train, Yg_train)\n",
    "Y_pred = clf.predict(Xg_test)\n",
    "\n",
    "gmulti_acc = accuracy_score(Yg_test, Y_pred)\n",
    "gmulti_f1 = f1_score(Yg_test, Y_pred, average='weighted') \n",
    "\n",
    "print(\"Précision : {}\".format(gmulti_acc))\n",
    "print(\"Score F1 : {}\".format(gmulti_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que l'utilisation de la loi multinomiale avec les hyperparamètres `MinMaxScaler` et `K-Bins discretization` donne une meilleure précision et score F1. Nous allons donc les utiliser pour la validation croisée.\n",
    "\n",
    "#### Bayes - Loi multinomiale - avec validation croisee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8009194601819851\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "clf = MultinomialNB(alpha=selected_alpha)\n",
    "scores = cross_val_score(clf, Xg_scaled, Y_galaxy, cv= K)\n",
    "print(sum(scores)/K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant effectuer le test de classification pour la loi multinomiale avec les primitives calculées dans le TP1, ajoutées aux autres primitives données dans le TP2. En effet, puisque nous avons trouvé une incohérence dans les deux datasets précédemment, nous avons préféré ne pas utiliser au début de nos analyses ces données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7943571144847276\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "clf = MultinomialNB(alpha=selected_alpha)\n",
    "XgTP1_scaled = scaler.fit_transform(X_galaxy_TP1_1)\n",
    "gmulti_scores = cross_val_score(clf, XgTP1_scaled, Y_galaxy, cv= K)\n",
    "print(sum(gmulti_scores)/K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Méthode de création des ensembles de données\n",
    "\n",
    "Nous avons essentiellement utilisé les méthodes de la librairie `Scikitlearn` pour créer nos ensembles de données. Nous utilisons `train_test_split` pour entraîner des algorithmes avec des validations en holdout, et `cross_val_score` pour des entraînements avec validation croisée. Cette librairie nous offre des moyens simples d'utilisation pour générer des ensembles de tailles pré-déterminée (20% des données sont resevées au test et 80% pour l'entraînement) en respectant les proportions respectives de chaque classe dans le jeu de données et ce pour simuler des conditions au plus proche d'un cas d'utilisation réelle compte tenu de nos données.La validation croisée avec permet d'utiliser plus efficacement le jeu de données tout en gardant une complexité raisonnable.\n",
    "Nous avons aussi utilisé Pandas qui est une librairie permettant de mieux gérer des données structurées (`dataframes`). Nos données `Galaxies` sont constituées des primitives données pour le TP2 ainsi que nos anciennes primitives concaténées. Cependant, nous avons remarqué une inconsistance dans les étiquettes, c'est pourquoi, pour certains de nos tests, nous n'utilisons que les données données.Les vecteurs de caracteristiques pour les `Galaxies` contiennent bien les étiquettes dans la dernière colonne mais rien n'indique les noms des fichiers correspondants et il est donc difficile de faire le lien avec le fichier des primitives calculées lors du TP1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### Approche de validation proposée et justification\n",
    "Nous avons choisi de pratiquer des validations croisées pour valider la totalité de nos apprentissages car nous pensons que c'est le meilleur compromis parmi K-fold cross-validation, leave-one-out, leave-P-out (coûteuses en resources) et holdout (coûteux en données). En effet,cette technique de validation nous permet de tester suffisamment de cas de figures d'entraînement pour être confiant sur l'apprentissage suffisamment général par rapport à holdout mais sans pour autant être aussi gourmand en ressources que leave-one-out ou leave-P-out. La méthode holdout permet de tester rapidement nos méthodes de classification et pour avoir une idée de l'erreur entre les véritables données, mais pour avoir l'erreur la plus représentatrice, nous utilisons ensuite les validations croisées. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Matrice des expérimentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|Données|Pourriels|Galaxies|\n",
       "|-------|---------|--------|\n",
       "|Arbre de décision d=3|Acc = 0.8985507246376812, F1 = 0.897740031205263|None|\n",
       "|Arbre de décision d=5|Acc = 0.9003623188405797, F1 = 0.8990733553257645|None|\n",
       "|Arbre de décision d=10|Acc = 0.9166666666666666, F1 = 0.9160850056088745|None|\n",
       "|Arbre de décision d=None|Acc = 0.9130434782608695, F1 = 0.9130434782608695|None|\n",
       "|Arbre de décision 10-CV|0.9195562848703643|None|\n",
       "|3-NN Uniform|Acc = 0.8188405797101449, F1 = 0.818407660148391|Acc = 0.5467179183914843, F1 = 0.546580009350169|\n",
       "|3-NN Distance|Acc = 0.8297101449275363, F1 = 0.8297101449275363|Acc = 0.539030159668835, F1 = 0.538831071662403|\n",
       "|5-NN Uniform|Acc = 0.8079710144927537, F1 = 0.807347603796286|Acc = 0.5582495564754583, F1 = 0.5580209973466429|\n",
       "|5-NN Distance|Acc = 0.8242753623188406, F1 = 0.8242086503869479|Acc = 0.5408042578356003, F1 = 0.5405746872272853|\n",
       "|10-NN Uniform|Acc = 0.7844202898550725, F1 = 0.7813752527940205|Acc = 0.5629804849201656, F1 = 0.5625866823342862|\n",
       "|10-NN Distance|Acc = 0.8278985507246377, F1 = 0.8275590465636746|Acc = 0.560615020697812, F1 = 0.5598099126473268|\n",
       "|3-NN Distance 10-CV|0.8029222185756482|0.5671851089912532|\n",
       "|Bayes Gaussian|Acc = 0.8387681159420289, F1 = 0.8402037805334562|Acc = 0.797752808988764, F1 = 0.797131047668415|\n",
       "|Bayes Multinomial|Acc = 0.907608695652174, F1 = 0.9081476031094811|Acc = 0.7965700768775872, F1 = 0.7965745650692521|\n",
       "|Bayes Multinomial 10-CV|0.8804200853298326|0.7943571144847276|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\"\"\"|Données|Pourriels|Galaxies|\n",
    "|-------|---------|--------|\n",
    "|Arbre de décision d=3|Acc = {0}, F1 = {1}|None|\n",
    "|Arbre de décision d=5|Acc = {2}, F1 = {3}|None|\n",
    "|Arbre de décision d=10|Acc = {4}, F1 = {5}|None|\n",
    "|Arbre de décision d=None|Acc = {6}, F1 = {7}|None|\n",
    "|Arbre de décision 10-CV|{8}|None|\n",
    "|3-NN Uniform|Acc = {9}, F1 = {10}|Acc = {11}, F1 = {12}|\n",
    "|3-NN Distance|Acc = {13}, F1 = {14}|Acc = {15}, F1 = {16}|\n",
    "|5-NN Uniform|Acc = {17}, F1 = {18}|Acc = {19}, F1 = {20}|\n",
    "|5-NN Distance|Acc = {21}, F1 = {22}|Acc = {23}, F1 = {24}|\n",
    "|10-NN Uniform|Acc = {25}, F1 = {26}|Acc = {27}, F1 = {28}|\n",
    "|10-NN Distance|Acc = {29}, F1 = {30}|Acc = {31}, F1 = {32}|\n",
    "|3-NN Distance 10-CV|{33}|{34}|\n",
    "|Bayes Gaussian|Acc = {35}, F1 = {36}|Acc = {37}, F1 = {38}|\n",
    "|Bayes Multinomial|Acc = {39}, F1 = {40}|Acc = {41}, F1 = {42}|\n",
    "|Bayes Multinomial 10-CV|{43}|{44}|\n",
    "\"\"\".format(sthree_acc[1], sthree_f1[1], sthree_acc[2], sthree_f1[2], sthree_acc[3], sthree_f1[3], sthree_acc[0], sthree_f1[0], \n",
    "           sum(sthree_CV_scores)/10, sKNN_acc_uniform[0], sKNN_f1_uniform[0], gKNN_acc_uniform[0], gKNN_f1_uniform[0], \n",
    "           sKNN_acc_distance[0], sKNN_f1_distance[0], gKNN_acc_distance[0], gKNN_f1_distance[0], \n",
    "           sKNN_acc_uniform[1], sKNN_f1_uniform[1], gKNN_acc_uniform[1], gKNN_f1_uniform[1], \n",
    "           sKNN_acc_distance[1], sKNN_f1_distance[1], gKNN_acc_distance[1], gKNN_f1_distance[1],\n",
    "           sKNN_acc_uniform[2], sKNN_f1_uniform[2], gKNN_acc_uniform[2], gKNN_f1_uniform[2], \n",
    "           sKNN_acc_distance[2], sKNN_f1_distance[2], gKNN_acc_distance[2], gKNN_f1_distance[2],\n",
    "           sum(sKNN_scores)/10, sum(gKNN_scores)/nfold,\n",
    "           sgauss_acc, sgauss_f1, ggauss_acc, ggauss_f1,\n",
    "           smulti_acc, smulti_f1, gmulti_acc, gmulti_f1,\n",
    "           sum(smulti_scores)/10, sum(gmulti_scores)/K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude des hyperparamètres\n",
    "\n",
    "#### Arbres de décision  \n",
    "\n",
    "D'après nos données, ne pas limiter la profondeur de l'abre créee un sur-apprentissage, il est donc préférable de limiter celle-ci. Pour les 3 valeurs testées ,plus la profondeur de l'arbre est élevée, plus la précision et les scores F1 sont élevés.\n",
    "Le gain d'information et donc la pureté de nos ensembles de données s'améliore en augmentant cette profondeur.Dans le cas des données de spams, Une profondeur de 10 ne semble pas causer de sur-apprentissage et permet d'obtenir les meilleurs résultats avec un F1 score de 0.9185.Cependant avec une prodondeur de 5 le F1 score est assez proche 0.90759 et dépendemment de l'application que l'on souhaite mettre en place il faudra prendre en compte la complexité de le l'arbre et une profondeur de 5 semble etre un bon compromis complexité/performance.\n",
    "\n",
    "#### KNN  \n",
    "`poids = uniform` veut dire que la pondération de chaque voisin est uniforme et ne dépend pas de la distance au point.\n",
    "L'option `poids = distance` pondère différement chaque voisin pour la décision de l'algorithme KNN. Cette pondération est inversement proportionnelle a la distance au point a classifier.\n",
    "La distance utilisée est celle par defaut donc ‘minkowski’ avec p=2 ce qui équivaut à la distance Euclidienne.\n",
    "\n",
    "Dans le cas des spams, les meilleurs hyperparamètres sont : `nombre de voisins = 3` et `poids = distance`. Nous pouvons expliquer cela par le fait que lorsque k est trop grand, le biais est important et on risque un sous-apprentissage. `K = 3` semble etre un bon compromis biais/variance sans introduire de sur-apprentissage. La performance de cet algorithme est également a prendre en compte car la pondération par distance introduit de la lenteur dans l'exécution O(nd+nk).\n",
    "\n",
    "Pour les galaxies, les meilleurs hyperparamètres sont : `nombre de voisins = 10` et `poids = distance`. Le nombre de voisins optimal est supérieur que pour les données `spam` car les données sont plus éparses. En effet, les galaxies sont des images, et la classification d'images grâce à leurs primitives est généralement plus difficile que pour des données plus \"directes\" comme le nombre de mots dans un mail... Il faut donc un nombre de voisins plus élevé pour que le choix soit plus optimal. Cependant ce modèle ne semble pas adapté à ce jeu de données.\n",
    "\n",
    "\n",
    "Nous pouvons remarquer que lorsque l'hyperparamètre du poids est égal à $distance$, les résultats sont significativement meilleurs. En effet, les voisins les plus proches aideront à mieux discriminer le point étudié.\n",
    "\n",
    "\n",
    "#### Bayes \n",
    "\n",
    "Deux hypothèses de distributions ont été étudiées dans ce projet, la loi normale et la distribution multinomiale. Pour cette dernière, il s'agit d'une généralisation de la loi de Bernouilli (succès de n épreuves) pour des variables de nature catégorielle (discrètes) comme c'est le cas pour `spam` ou `galaxies`.\n",
    "\n",
    "L'impact de l'hyperparamètre alpha a été évalué pour cette distribution pour la classifiaction de galaxies. Alpha est un hyperparamètre de lissage pour les variables catégorielles.\n",
    "\n",
    "\n",
    "Pour nos deux jeux de données, le meilleur résultat sont obtenus grâce à l'algorithme de Bayes naïf multinomial, avec `MinMaxScaler` et la `K-Bins discretization`.   \n",
    "\n",
    "D'après la définition de Scikit-learn, `MinMaxScaler` transforme les primitives en les mettant à l'échelle entre 0 et 1. Cela permet de minimiser les différences d'échelle entre les différents attributs. (Ex : un attribut entre 0 et 1000 et un attribut entre 0 et 1).\n",
    "\n",
    "`KBinsDiscretizer` permet de discrétiser les attributs continus que nous avons en entrée. Cela permet de réduire les différences entre les différentes valeurs que peut prendre l'attribut, ce qui permet de mieux les regrouper entre eux.\n",
    "\n",
    "Ces meilleurs résultats peuvent s'expliquer par le fait que pour les algorithmes, il est plus facile de différencier des valeurs discrètes qu'une infinité de valeurs différentes (ce qui semble assez logique). En effet, une partie de la classification est déjà faite sur les primitives. De plus, mettre à l'échelle les différentes primitives permet de ne pas sur-interpréter les données qui sont sur une grande échelle. \n",
    "\n",
    "#### Forêts aléatoires (random forest)\n",
    "\n",
    "Les hyperparamètres pour le modèle des forêts aléatoires ont été déterminés avec une recherche par grille (`Grid Search`). La profondeur des arbres (max_depth) est un hyperparamètre a considérer ainsi que le nombre d'arbres (n_estimators).La profondeur maximale utilisée est 20 avec 30 arbres.La profondeur de l'arbre a un impact sur la generalisation de l'algorithme a de nouvelles données et plus l'arbre est profond plus la variance et grande avec un biais faible (possibilités de sur-apprentissage)\n",
    "A 'inverse, un arbre trop peu profond a une petite variance mais un biais (erreur) élevé,c'est le cas du sous-apprentissage. La Sensibilité au bruit des arbres de décison peut etre attenuee avec les forets aleatoires en introduisant un vote des arbres pour la classe majoritaitre.L'hyperparamètre `n_estimators` correspond au nombre d'arbres et ameliore globalement les performances de classifications avec un n élevé mais les ressources mémoire consomées augmentent (n=300 dans notre analyse).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "### Impact de la taille des ensembles de données sur la performance de classification\n",
    "\n",
    "D'après nos différentes analyses, les ensembles de données qui se démarquent le mieux sont ceux dont les attributs sont discrétisés. En effet, comme expliqué précédemment, cela permet de regrouper un ensemble de valeurs différentes. Pour ce qui est de la taille des ensembles de données, nous avons beaucoup moins d'exemples pour `Spam` que pour `Galaxies`. Cependant, le cas des spams donne des erreurs beaucoup plus faibles que le cas des galaxies. Nous pouvons expliquer cela par le fait que les primitives de Spam sont plus discriminantes que celles des galaxies. Nous pouvons donc déduire de ces exemples que la taille des ensembles des données n'aide pas forcément à une meilleure classification des données. En effet, la qualité des primitives joue un rôle principal dans les performances de classification. Cependant, lorsque les privitives discriminent bien les données par essence,une augmentation du nombre d'observations permettre d'améliorer les performances de classification des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "### Impact du bruit dans les ensembles de données sur la performance de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sait que les données extraites de l'analyse des images de galaxies sont plus bruitées que celles extraites des courriels.Une étape de nettoyage des données avant l'extraction des primitives permettra de limiter l'impact du bruit.\n",
    "Par conséquent en testant chaque classifieur avec les mêmes hyperparamètres pour nos deux problématiques de classification, nous sommes en mesure de comparer l'impact du bruit sur la classification.\n",
    "Etant donné que nous avons déja constaté que les résultats des arbres de classification n'étaient pas très bons, nous pouvons conclure que ce type de classification est très sensible au bruit. D'ailleurs, pour la classification des courriels, on obtient un score de plus de 90% comparé au 75% pour les galaxies dans le lab précédent.\n",
    "\n",
    "D'après les observations des résultas de KNN, il semblerait que ce classifieur soit encore plus sensible au bruit que les arbres de classification.\n",
    "\n",
    "D'un autre côté les classifieurs naïfs guassiens ou multinomiaux semblent moins sensibles au bruit mais n'améliorent pas la classification d'un ensemble peu bruité comparé aux résultats obtenus dans KNN ou par arbres de décision avec les courriels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "### Discussion sur la nature des données\n",
    "\n",
    "Les données `Spam` sont extraites de différents mails, qui sont eux même composés d'une série de mots. Les données `Galaxy` sont quant à elles des images. Il est clairement plus difficile d'extraire de bonnes primitives discriminantes sur des images que sur du texte. En effet, il faut tout d'abord effectuer plusieurs pré-traitements sur les images pour pouvoir extraire des données qui ne sont pas complètement sûres, par rapport à un nombre d'enchainement de mots écrits en majuscule dans un texte par exemple.  \n",
    "C'est pourquoi nous arrivons mieux à classifier les mails en Spam que les différents types de galaxies.\n",
    "\n",
    "Pour les données comme `Spam`, le meilleur algorithme est celui des arbres de décision (et des forets aleatoires), d'après le tableau de résultats. En effet, il est plus facile de donner un seuil pour ces variables qui va classifier au mieux nos données. Les algorithmes KNN sont moins performants car nous avons 57 attributs donc autant de dimensions. La notion de distance dans 57 dimensions n'est pas assez discriminante. \n",
    "Pour les données de Spam , il est judicieux d'utiliser une méthode d'estimation paramétrique car l'hypothese d'une distribution multinomiale est plausible.L'algorithme Bayésien naïf a une performance similaire aux arbres de décision pour les raisons expliquées dans la question 3 (l'estimation d'une distribution multinomiale se prete bien a ce cas de figure).\n",
    "\n",
    "Pour les données `Galaxies`, les deux algorithmes de Bayes naïf s'équivalent. Les mêmes raisons s'appliquent pour le multinomial.Lorsque le Nombre d'echantillions est assez grand,la distribution multinomiale tend vers une Gaussienne ce qui explique que les performances s'équivalent. Pour le cas gaussien, il permet d'atténuer de manière significative les valeurs abérrentes, qui se trouvent en quantité considérable dans notre jeu de données. C'est justement l'énorme portée des variables ainsi que l'incertitude liée à nos primitives qui rendent les algorithmes des arbres de décision peu efficaces pour cette nature de données.De même, comme expliqué précédemment, le bruit limite toute chance au KNN de bien classifier nos données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "### Recommandations\n",
    "\n",
    "Après avoir anaylisé les résultats, nous pouvons en déduire un ensemble de pratiques pertinentes a mettre en oeuvre en fonction de la nature des données qui nous sont proposées.\n",
    "Tout d'abord, lorsque pour la classification d'images il semble essentiel de discrétiser les caractéristiques de sorte à réduire l'impact du bruit sur la prise de décision. Cela semble être un traitement qui va dans le sens de la généralisation de l'apprentissage. Les caractéristiques une fois discrétisées sont alors mieux adaptées à des méthodes de classification Bayésiennes telles que des classifieurs Gaussiens ou Multinomiaux.\n",
    "\n",
    "Pour des données moins bruitées il nous semble qu'aucune technique de classification ne prévale au vu de nos résultats, cependant nous savons que toutes les techniques ne sont pas aussi gourmandes en ressources mémoire ou temps de calcul. Partant de ce constat, les méthodes KNN sont trop gourmandes ( O(nd+nk) et aussi légèrement moins précises) et donc à éviter si possible. KNN fonctionne mieux pour un nombre plus limité de caractéristiques et ou la notion de distance est pertinente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "### Améliorations possibles\n",
    "\n",
    "Pour les données `Spam`, si nous voulons appliquer l'algorithme des K-PPV, nous pouvons réduire la dimensionnalité des attributs pour enlever ceux qui sont les plus correlés entre eux (décrire l'objet avec un nombre minime d'attributs qui ne sont pas liés les uns aux autres). Cela permettrait d'améliorer la notion de distance pour mieux discriminer les pourriels.\n",
    "\n",
    "Pour les données `Galaxies`, nous avons vu que les quelques méthodes discrétisation et de mises à l'échelle étaient très efficaces. Il existe sûrement d'autres méthodes que nous aurions pu utiliser pour améliorer notre classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
